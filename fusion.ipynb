{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "p4U8rQW59irD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import torch.optim as optim\n",
        "from torch_geometric.nn import TransformerConv\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch import tensor\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "from collections import defaultdict\n",
        "\n",
        "import torch.utils.data as data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yHV2yinbaXBN"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "def load_data(dataset, device):\n",
        "    data_file = f\"./original_datasets/{dataset}/{dataset}_train\"\n",
        "    file = open(data_file, \"r\")\n",
        "    node_types = set()\n",
        "    label_types = set()\n",
        "    tr_len = 0\n",
        "    for line in file:\n",
        "        tr_len += 1\n",
        "        smiles = line.split(\"\\t\")[1]\n",
        "        s = []\n",
        "        mol = AllChem.MolFromSmiles(smiles)\n",
        "        for atom in mol.GetAtoms():\n",
        "            s.append(atom.GetAtomicNum())\n",
        "        node_types |= set(s)\n",
        "        label = line.split(\"\\t\")[2][:-1]\n",
        "        label_types.add(label)\n",
        "    file.close()\n",
        "\n",
        "    te_len = 0\n",
        "    data_file = f\"./original_datasets/{dataset}/{dataset}_test\"\n",
        "    file = open(data_file, \"r\")\n",
        "    for line in file:\n",
        "        te_len += 1\n",
        "        smiles = line.split(\"\\t\")[1]\n",
        "        s = []\n",
        "        mol = AllChem.MolFromSmiles(smiles)\n",
        "        for atom in mol.GetAtoms():\n",
        "            s.append(atom.GetAtomicNum())\n",
        "        node_types |= set(s)\n",
        "        label = line.split(\"\\t\")[2][:-1]\n",
        "        label_types.add(label)\n",
        "    file.close()\n",
        "\n",
        "    #print(tr_len)\n",
        "    #print(te_len)\n",
        "\n",
        "    node2index = {n: i for i, n in enumerate(node_types)}\n",
        "    label2index = {l: i for i, l in enumerate(label_types)}\n",
        "\n",
        "    #print(node2index)\n",
        "    #print(label2index)\n",
        "\n",
        "    data_file = f\"./original_datasets/{dataset}/{dataset}_train\"\n",
        "    file = open(data_file, \"r\")\n",
        "    train_adjlists = []\n",
        "    train_features = []\n",
        "    train_sequence = []\n",
        "    train_labels = torch.zeros(tr_len)\n",
        "    for line in file:\n",
        "        smiles = line.split(\"\\t\")[1]\n",
        "        label = line.split(\"\\t\")[2][:-1]\n",
        "        mol = AllChem.MolFromSmiles(smiles)\n",
        "        feature = torch.zeros(len(mol.GetAtoms()), len(node_types))\n",
        "\n",
        "        l = 0\n",
        "        smiles_seq = []\n",
        "        for atom in mol.GetAtoms():\n",
        "            feature[l, node2index[atom.GetAtomicNum()]] = 1\n",
        "            smiles_seq.append(node2index[atom.GetAtomicNum()])\n",
        "            l += 1\n",
        "        adj_list = defaultdict(list)\n",
        "        for bond in mol.GetBonds():\n",
        "            i = bond.GetBeginAtomIdx()\n",
        "            j = bond.GetEndAtomIdx()\n",
        "            typ = bond.GetBondType()\n",
        "            adj_list[i].append(j)\n",
        "            adj_list[j].append(i)\n",
        "            if typ == Chem.rdchem.BondType.DOUBLE:\n",
        "                adj_list[i].append(j)\n",
        "                adj_list[j].append(i)\n",
        "            elif typ == Chem.rdchem.BondType.TRIPLE:\n",
        "                adj_list[i].append(j)\n",
        "                adj_list[j].append(i)\n",
        "                adj_list[i].append(j)\n",
        "                adj_list[j].append(i)\n",
        "\n",
        "        train_labels[len(train_adjlists)]= int(label2index[label])\n",
        "        #print(train_labels)\n",
        "        train_adjlists.append(adj_list)\n",
        "        train_features.append(torch.FloatTensor(feature).to(device))\n",
        "        train_sequence.append(torch.tensor(smiles_seq))\n",
        "    file.close()\n",
        "\n",
        "    data_file = f\"./original_datasets/{dataset}/{dataset}_test\"\n",
        "    file = open(data_file, \"r\")\n",
        "    test_adjlists = []\n",
        "    test_features = []\n",
        "    test_sequence = []\n",
        "    test_labels = np.zeros(te_len)\n",
        "    for line in file:\n",
        "        smiles = line.split(\"\\t\")[1]\n",
        "        # print(smiles)\n",
        "        label = line.split(\"\\t\")[2][:-1]\n",
        "        mol = AllChem.MolFromSmiles(smiles)\n",
        "        feature = torch.zeros(len(mol.GetAtoms()), len(node_types))\n",
        "        l = 0\n",
        "        smiles_seq = []\n",
        "        for atom in mol.GetAtoms():\n",
        "            feature[l, node2index[atom.GetAtomicNum()]] = 1\n",
        "            smiles_seq.append(node2index[atom.GetAtomicNum()])\n",
        "            l += 1\n",
        "        adj_list = defaultdict(list)\n",
        "        for bond in mol.GetBonds():\n",
        "            i = bond.GetBeginAtomIdx()\n",
        "            j = bond.GetEndAtomIdx()\n",
        "            typ = bond.GetBondType()\n",
        "            adj_list[i].append(j)\n",
        "            adj_list[j].append(i)\n",
        "            if typ == Chem.rdchem.BondType.DOUBLE:\n",
        "                adj_list[i].append(j)\n",
        "                adj_list[j].append(i)\n",
        "            elif typ == Chem.rdchem.BondType.TRIPLE:\n",
        "                adj_list[i].append(j)\n",
        "                adj_list[j].append(i)\n",
        "                adj_list[i].append(j)\n",
        "                adj_list[j].append(i)\n",
        "\n",
        "        test_labels[len(test_adjlists)] = int(label2index[label])\n",
        "        test_adjlists.append(adj_list)\n",
        "        test_features.append(torch.FloatTensor(feature).to(device))\n",
        "        test_sequence.append(torch.tensor(smiles_seq))\n",
        "    file.close()\n",
        "    train_data = {}\n",
        "    train_data['adj_lists'] = train_adjlists\n",
        "    train_data['features'] = train_features\n",
        "    # Pad train_sequence to length 100\n",
        "    padded_train_sequence = []\n",
        "    for seq in train_sequence:\n",
        "      padded_seq = torch.nn.functional.pad(seq, (0, 100 - len(seq)), 'constant', 0)\n",
        "      padded_train_sequence.append(padded_seq)\n",
        "      train_data['sequence'] = padded_train_sequence\n",
        "    test_data = {}\n",
        "    test_data['adj_lists'] = test_adjlists\n",
        "    test_data['features'] = test_features\n",
        "    padded_test_sequence = []\n",
        "    for seq in test_sequence:\n",
        "      padded_seq = torch.nn.functional.pad(seq, (0, 100 - len(seq)), 'constant', 0)\n",
        "      padded_test_sequence.append(padded_seq)\n",
        "      test_data['sequence'] = padded_test_sequence\n",
        "\n",
        "    return train_data, train_labels, test_data, test_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2bJwYJKB9wzS"
      },
      "outputs": [],
      "source": [
        "train_data, train_labels, test_data, test_labels=load_data(\"fda\",device='cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqRk_GmJ-Kll",
        "outputId": "6eadb4bd-06d8-4c66-a4ab-1a7a55af3696"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\vysha\\AppData\\Local\\Temp\\ipykernel_115248\\3184463301.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  logp_data_list_train = [Data(x=torch.tensor(features, dtype=torch.float),\n",
            "C:\\Users\\vysha\\AppData\\Local\\Temp\\ipykernel_115248\\3184463301.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  y=torch.tensor(label, dtype=torch.float))\n",
            "C:\\Users\\vysha\\AppData\\Local\\Temp\\ipykernel_115248\\3184463301.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  logp_data_list_test= [Data(x=torch.tensor(features, dtype=torch.float),\n",
            "C:\\Users\\vysha\\AppData\\Local\\Temp\\ipykernel_115248\\3184463301.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  y=torch.tensor(label, dtype=torch.float))\n"
          ]
        }
      ],
      "source": [
        "logp_input_dim_train = train_data['features'][0].size(-1)\n",
        "logp_input_dim_test = test_data['features'][0].size(-1)\n",
        "def adj_list_to_adj_matrix(adj_list):\n",
        "    num_nodes = len(adj_list)\n",
        "    adj_matrix = torch.zeros((num_nodes, num_nodes), dtype=torch.float)\n",
        "    for node, neighbors in adj_list.items():\n",
        "        for neighbor in neighbors:\n",
        "            adj_matrix[node][neighbor] = 1.0\n",
        "            adj_matrix[neighbor][node] = 1.0\n",
        "    return adj_matrix\n",
        "logp_adj_matrices_train = [adj_list_to_adj_matrix(adj_list) for adj_list in train_data['adj_lists']]\n",
        "logp_adj_matrices_test = [adj_list_to_adj_matrix(adj_list) for adj_list in test_data['adj_lists']]\n",
        "\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Combine data and sequence into one tensor for both train and test data\n",
        "logp_data_sequence_train = torch.stack(train_data['sequence'])\n",
        "logp_data_sequence_test = torch.stack(test_data['sequence'])\n",
        "\n",
        "logp_data_list_train = [Data(x=torch.tensor(features, dtype=torch.float),\n",
        "                  edge_index=torch.nonzero(adj_matrix, as_tuple=False).t().contiguous(),\n",
        "                  y=torch.tensor(label, dtype=torch.float))\n",
        "             for features, adj_matrix, label in zip(train_data['features'], logp_adj_matrices_train, train_labels)]\n",
        "logp_data_list_test= [Data(x=torch.tensor(features, dtype=torch.float),\n",
        "                  edge_index=torch.nonzero(adj_matrix, as_tuple=False).t().contiguous(),\n",
        "                  y=torch.tensor(label, dtype=torch.float))\n",
        "             for features, adj_matrix, label in zip(test_data['features'], logp_adj_matrices_test, train_labels)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ui66hoXM2JSC"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_list, sequence_list):\n",
        "        self.data_list = data_list\n",
        "        self.sequence_list = sequence_list\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        data = self.data_list[index]\n",
        "        sequence = self.sequence_list[index]\n",
        "        return data, sequence\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_list)\n",
        "\n",
        "\n",
        "def custom_collate(batch):\n",
        "  if isinstance(batch[0], Data):\n",
        "    # Convert each Data object in the batch to a dictionary.\n",
        "    batch = [data.__dict__ for data in batch]\n",
        "    # Return a new Data object with the dictionaries as its attributes.\n",
        "    return Data(**batch[0])\n",
        "  else:\n",
        "    # Handle other types of data as needed.\n",
        "    pass\n",
        "# Create datasets\n",
        "train_dataset = CustomDataset(logp_data_list_train, train_data['sequence'])\n",
        "test_dataset = CustomDataset(logp_data_list_test, test_data['sequence'])\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=False,collate_fn=custom_collate)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False,collate_fn=custom_collate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MmOC8mVFluj",
        "outputId": "3ae14c45-1c2d-45e0-be66-88f395b645c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sample size 2584\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Training loop\n",
        "for epoch in range(1):\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "    for data_batch in train_dataset:\n",
        "        graph_data_batch = data_batch[0]\n",
        "        sequence_inputs  = data_batch[1]\n",
        "        sequence_targets=graph_data_batch.y\n",
        "        total_samples += 1\n",
        "print(\"sample size\",total_samples)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

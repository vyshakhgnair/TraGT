{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "M0tj2GM33oTn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from datetime import datetime\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "import numpy as np\n",
        "import torch\n",
        "import numpy as np\n",
        "from rdkit.Chem import AllChem\n",
        "from rdkit import Chem\n",
        "from collections import defaultdict\n",
        "import os,time\n",
        "from torch_geometric.data import Data\n",
        "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AJW8OtDUEcly"
      },
      "outputs": [],
      "source": [
        "def load_data_long(dataset, device):\n",
        "    mole_dict = {1: \"H\", 2: \"He\", 3: \"Li\", 4: \"Be\", 5: \"B\", 6: \"C\", 7: \"N\", 8: \"O\", 9: \"F\", 10: \" Ne\",\n",
        "                11: \"Na\", 12:\"Mg\", 13: \"Al\", 14:\"Si\", 15:\"P\", 16: \"S\", 17: \"Cl\", 18:\"Ar\", 19:\"K\", 20:\"Ca\", 22:\"Ti\", 24:\"Cr\", 26:\"Fe\", 28:\"Ni\",\n",
        "                29:\"Cu\", 31:\"Ga\", 32:\"Ge\", 34:\"Se\", 35:\"Br\", 40:\"Zr\", 44:\"Ru\", 45:\"Rh\", 46:\"Pd\", 47:\"Ag\", 50:\"Sn\", 51:\"Sb\", 52:\"Te\", 53: \"I\", 65:\"Tb\", 75:\"Re\", 77:\"Ir\", 78:\"Pt\", 79:\"Au\", 80:\"Hg\",\n",
        "                81:\"Tl\", 82:\"Pb\", 83:\"Bi\"}\n",
        "\n",
        "    pair_list = [\"Br\", \"Cl\", \"Si\", \"Na\", \"Ca\", \"Ge\", \"Cu\", \"Au\", \"Sn\", \"Tb\", \"Pt\", \"Re\", \"Ru\", \"Bi\", \"Li\", \"Fe\", \"Sb\", \"Hg\",\"Pb\", \"Se\", \"Ag\",\"Cr\",\"Pd\",\"Ga\",\"Mg\",\"Ni\",\"Ir\",\"Rh\",\"Te\",\"Ti\",\"Al\",\"Zr\",\"Tl\"]\n",
        "\n",
        "    data_file = f\"./original_datasets/{dataset}/{dataset}_train\"\n",
        "    file = open(data_file, \"r\")\n",
        "    node_types = set()\n",
        "    label_types = set()\n",
        "    tr_len = 0\n",
        "    for line in file:\n",
        "        tr_len += 1\n",
        "        smiles = line.split(\"\\t\")[1]\n",
        "        label = line.split(\"\\t\")[2][:-1]\n",
        "        i = 0\n",
        "        s = []\n",
        "        while i < len(smiles):\n",
        "            if i < len(smiles)-1 and (smiles[i] + smiles[i+1]) in pair_list:\n",
        "                s.append(smiles[i] + smiles[i+1])\n",
        "                i += 2\n",
        "            else:\n",
        "                s.append(smiles[i].upper())\n",
        "                i += 1\n",
        "        node_types |= set(s)\n",
        "        label_types.add(label)\n",
        "    file.close()\n",
        "\n",
        "    te_len = 0\n",
        "    data_file = f\"./original_datasets/{dataset}/{dataset}_test\"\n",
        "    file = open(data_file, \"r\")\n",
        "    for line in file:\n",
        "        te_len += 1\n",
        "        smiles = line.split(\"\\t\")[1]\n",
        "        label = line.split(\"\\t\")[2][:-1]\n",
        "        i = 0\n",
        "        s = []\n",
        "        while i < len(smiles):\n",
        "            if i < len(smiles)-1 and (smiles[i] + smiles[i+1]) in pair_list:\n",
        "                s.append(smiles[i] + smiles[i+1])\n",
        "                i += 2\n",
        "            else:\n",
        "                s.append(smiles[i].upper())\n",
        "                i += 1\n",
        "        node_types |= set(s)\n",
        "        label_types.add(label)\n",
        "    file.close()\n",
        "\n",
        "    #print(tr_len)\n",
        "    #print(te_len)\n",
        "\n",
        "    node2index = {n: i for i, n in enumerate(node_types)}\n",
        "    label2index = {l: i for i, l in enumerate(label_types)}\n",
        "\n",
        "    #print(node2index)\n",
        "    #print(label2index)\n",
        "\n",
        "    data_file = f\"./original_datasets/{dataset}/{dataset}_train\"\n",
        "    file = open(data_file, \"r\")\n",
        "    train_adjlists = []\n",
        "    train_features = []\n",
        "    train_sequence = []\n",
        "    train_labels = torch.zeros(tr_len)\n",
        "    for line in file:\n",
        "        smiles = line.split(\"\\t\")[1]\n",
        "        label = line.split(\"\\t\")[2][:-1]\n",
        "        mol = AllChem.MolFromSmiles(smiles)\n",
        "        graph_nodes = []\n",
        "        for atom in mol.GetAtoms():\n",
        "            graph_nodes.append(mole_dict[atom.GetAtomicNum()])\n",
        "        # print(graph_nodes)\n",
        "        i = 0\n",
        "        s = 0\n",
        "        while i < len(smiles):\n",
        "            if i < len(smiles)-1 and (smiles[i] + smiles[i+1]) in pair_list:\n",
        "                i += 2\n",
        "            else:\n",
        "                i += 1\n",
        "            s += 1\n",
        "\n",
        "        feature = torch.zeros(s, len(node_types))\n",
        "\n",
        "        map = {}\n",
        "        se_num = 0\n",
        "        gr_num = 0\n",
        "        i = 0\n",
        "        smiles_seq = []\n",
        "        while i < len(smiles):\n",
        "            this_str = smiles[i]\n",
        "            if i < len(smiles)-1 and (smiles[i] + smiles[i+1]) in pair_list:\n",
        "                this_str = smiles[i] + smiles[i+1]\n",
        "                i += 2\n",
        "            else:\n",
        "                this_str = this_str.upper()\n",
        "                i += 1\n",
        "            smiles_seq.append(node2index[this_str])\n",
        "            if this_str in graph_nodes and this_str == mole_dict[mol.GetAtoms()[gr_num].GetAtomicNum()]:\n",
        "                map[gr_num] = se_num\n",
        "                gr_num += 1\n",
        "            feature[se_num, node2index[this_str]] = 1\n",
        "            se_num += 1\n",
        "\n",
        "        adj_list = defaultdict(list)\n",
        "        for bond in mol.GetBonds():\n",
        "            i = bond.GetBeginAtomIdx()\n",
        "            j = bond.GetEndAtomIdx()\n",
        "            # print(i,j)\n",
        "            typ = bond.GetBondType()\n",
        "            adj_list[map[i]].append(map[j])\n",
        "            adj_list[map[j]].append(map[i])\n",
        "            if typ == Chem.rdchem.BondType.DOUBLE:\n",
        "                adj_list[map[i]].append(map[j])\n",
        "                adj_list[map[j]].append(map[i])\n",
        "            elif typ == Chem.rdchem.BondType.TRIPLE:\n",
        "                adj_list[map[i]].append(map[j])\n",
        "                adj_list[map[j]].append(map[i])\n",
        "                adj_list[map[i]].append(map[j])\n",
        "                adj_list[map[j]].append(map[i])\n",
        "\n",
        "        # train_labels[len(train_adjlists)]= int(label2index[label])\n",
        "        train_labels[len(train_adjlists)]= int(label)\n",
        "        train_adjlists.append(adj_list)\n",
        "        train_features.append(torch.FloatTensor(feature).to(device))\n",
        "        train_sequence.append(torch.tensor(smiles_seq))\n",
        "    file.close()\n",
        "\n",
        "    data_file = f\"./original_datasets/{dataset}/{dataset}_test\"\n",
        "    file = open(data_file, \"r\")\n",
        "    test_adjlists = []\n",
        "    test_features = []\n",
        "    test_sequence = []\n",
        "    test_labels = np.zeros(te_len)\n",
        "    for line in file:\n",
        "        smiles = line.split(\"\\t\")[1]\n",
        "        # print(smiles)\n",
        "        label = line.split(\"\\t\")[2][:-1]\n",
        "        mol = AllChem.MolFromSmiles(smiles)\n",
        "        graph_nodes = []\n",
        "        for atom in mol.GetAtoms():\n",
        "            graph_nodes.append(mole_dict[atom.GetAtomicNum()])\n",
        "        # print(graph_nodes)\n",
        "        i = 0\n",
        "        s = 0\n",
        "        while i < len(smiles):\n",
        "            if i < len(smiles)-1 and (smiles[i] + smiles[i+1]) in pair_list:\n",
        "                i += 2\n",
        "            else:\n",
        "                i += 1\n",
        "            s += 1\n",
        "\n",
        "        feature = torch.zeros(s, len(node_types))\n",
        "\n",
        "        map = {}\n",
        "        se_num = 0\n",
        "        gr_num = 0\n",
        "        i = 0\n",
        "        smiles_seq = []\n",
        "        while i < len(smiles):\n",
        "            this_str = smiles[i]\n",
        "            if i < len(smiles)-1 and (smiles[i] + smiles[i+1]) in pair_list:\n",
        "                this_str = smiles[i] + smiles[i+1]\n",
        "                i += 2\n",
        "            else:\n",
        "                this_str = this_str.upper()\n",
        "                i += 1\n",
        "            smiles_seq.append(node2index[this_str])\n",
        "            if this_str in graph_nodes and this_str == mole_dict[mol.GetAtoms()[gr_num].GetAtomicNum()]:\n",
        "                map[gr_num] = se_num\n",
        "                gr_num += 1\n",
        "            feature[se_num, node2index[this_str]] = 1\n",
        "            se_num += 1\n",
        "\n",
        "        adj_list = defaultdict(list)\n",
        "        for bond in mol.GetBonds():\n",
        "            i = bond.GetBeginAtomIdx()\n",
        "            j = bond.GetEndAtomIdx()\n",
        "            # print(i,j)\n",
        "            typ = bond.GetBondType()\n",
        "            adj_list[map[i]].append(map[j])\n",
        "            adj_list[map[j]].append(map[i])\n",
        "            if typ == Chem.rdchem.BondType.DOUBLE:\n",
        "                adj_list[map[i]].append(map[j])\n",
        "                adj_list[map[j]].append(map[i])\n",
        "            elif typ == Chem.rdchem.BondType.TRIPLE:\n",
        "                adj_list[map[i]].append(map[j])\n",
        "                adj_list[map[j]].append(map[i])\n",
        "                adj_list[map[i]].append(map[j])\n",
        "                adj_list[map[j]].append(map[i])\n",
        "\n",
        "        # test_labels[len(test_adjlists)] = int(label2index[label])\n",
        "        test_labels[len(test_adjlists)] = int(label)\n",
        "        test_adjlists.append(adj_list)\n",
        "        test_features.append(torch.FloatTensor(feature).to(device))\n",
        "        test_sequence.append(torch.tensor(smiles_seq))\n",
        "    file.close()\n",
        "\n",
        "    train_data = {}\n",
        "    train_data['adj_lists'] = train_adjlists\n",
        "    train_data['features'] = train_features\n",
        "     # Pad train_sequence to length 100\n",
        "    padded_train_sequence = []\n",
        "    for seq in train_sequence:\n",
        "      padded_seq = torch.nn.functional.pad(seq, (0, 100 - len(seq)), 'constant', 0)\n",
        "      padded_train_sequence.append(padded_seq)\n",
        "      train_data['sequence'] = padded_train_sequence\n",
        "\n",
        "    test_data = {}\n",
        "    test_data['adj_lists'] = test_adjlists\n",
        "    test_data['features'] = test_features\n",
        "    padded_test_sequence = []\n",
        "    for seq in test_sequence:\n",
        "      padded_seq = torch.nn.functional.pad(seq, (0, 100 - len(seq)), 'constant', 0)\n",
        "      padded_test_sequence.append(padded_seq)\n",
        "      test_data['sequence'] = padded_test_sequence\n",
        "\n",
        "    return train_data, train_labels, test_data, test_labels\n",
        "\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data_list, sequence_list):\n",
        "        self.data_list = data_list\n",
        "        self.sequence_list = sequence_list\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        data = self.data_list[index]\n",
        "        sequence = self.sequence_list[index]\n",
        "        return data, sequence\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_list)\n",
        "    \n",
        "\n",
        "def adj_list_to_adj_matrix(adj_list):\n",
        "    num_nodes = max(adj_list.keys()) + 1\n",
        "    adj_matrix = torch.zeros((num_nodes, num_nodes), dtype=torch.float)\n",
        "    for node, neighbors in adj_list.items():\n",
        "        for neighbor in neighbors:\n",
        "            adj_matrix[node][neighbor] = 1.0\n",
        "            adj_matrix[neighbor][node] = 1.0\n",
        "    return adj_matrix\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uM-Ilen0Emg-"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[23:53:25] WARNING: not removing hydrogen atom without neighbors\n",
            "[23:53:25] WARNING: not removing hydrogen atom without neighbors\n",
            "[23:53:25] WARNING: not removing hydrogen atom without neighbors\n",
            "[23:53:25] WARNING: not removing hydrogen atom without neighbors\n",
            "[23:53:25] WARNING: not removing hydrogen atom without neighbors\n",
            "[23:53:25] WARNING: not removing hydrogen atom without neighbors\n",
            "[23:53:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[23:53:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[23:53:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[23:53:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[23:53:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[23:53:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[23:53:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[23:53:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[23:53:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[23:53:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[23:53:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[23:53:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[23:53:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[23:53:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[23:53:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[23:53:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[23:53:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[23:53:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[23:53:27] WARNING: not removing hydrogen atom without neighbors\n",
            "[23:53:27] WARNING: not removing hydrogen atom without neighbors\n",
            "[23:53:27] WARNING: not removing hydrogen atom without neighbors\n",
            "[23:53:27] WARNING: not removing hydrogen atom without neighbors\n",
            "[23:53:27] WARNING: not removing hydrogen atom without neighbors\n",
            "[23:53:27] WARNING: not removing hydrogen atom without neighbors\n",
            "[23:53:27] WARNING: not removing hydrogen atom without neighbors\n",
            "[23:53:27] WARNING: not removing hydrogen atom without neighbors\n",
            "[23:53:27] WARNING: not removing hydrogen atom without neighbors\n"
          ]
        }
      ],
      "source": [
        "train_data, train_labels, test_data, test_labels=load_data_long(\"bbbp\", device=\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41iy9iTUcfJb",
        "outputId": "5adac398-135c-469f-ce42-de6f9267d5eb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\vysha\\AppData\\Local\\Temp\\ipykernel_97780\\2688029661.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  data_list_train = [Data(x=torch.tensor(features, dtype=torch.float),\n",
            "C:\\Users\\vysha\\AppData\\Local\\Temp\\ipykernel_97780\\2688029661.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  y=torch.tensor(label, dtype=torch.float))\n",
            "C:\\Users\\vysha\\AppData\\Local\\Temp\\ipykernel_97780\\2688029661.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  data_list_test = [Data(x=torch.tensor(features, dtype=torch.float),\n"
          ]
        }
      ],
      "source": [
        "input_dim_train = train_data['features'][0].size(-1)\n",
        "input_dim_test = test_data['features'][0].size(-1)\n",
        "\n",
        "\n",
        "adj_matrices_train = [adj_list_to_adj_matrix(adj_list) for adj_list in train_data['adj_lists']]\n",
        "adj_matrices_test = [adj_list_to_adj_matrix(adj_list) for adj_list in test_data['adj_lists']]\n",
        "\n",
        "\n",
        "\n",
        "data_list_train = [Data(x=torch.tensor(features, dtype=torch.float),\n",
        "                              edge_index=torch.nonzero(adj_matrix, as_tuple=False).t().contiguous(),\n",
        "                              y=torch.tensor(label, dtype=torch.float))\n",
        "                         for features, adj_matrix, label in zip(train_data['features'], adj_matrices_train, train_labels)]\n",
        "data_list_test = [Data(x=torch.tensor(features, dtype=torch.float),\n",
        "                                edge_index=torch.nonzero(adj_matrix, as_tuple=False).t().contiguous(),\n",
        "                                y=torch.tensor(label, dtype=torch.float))\n",
        "                            for features, adj_matrix, label in zip(test_data['features'], adj_matrices_test, test_labels)]\n",
        "\n",
        "train_dataset = CustomDataset(data_list_train, train_data['sequence'])\n",
        "test_dataset = CustomDataset(data_list_test, test_data['sequence'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LjslxlhzbiDP"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, nhead, num_encoder_layers, dim_feedforward, max_length=100):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward), num_layers=num_encoder_layers)\n",
        "        self.fc = nn.Linear(d_model, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x).to(self.device)\n",
        "        x = torch.transpose(x, 0, 1).to(self.device)\n",
        "        x = self.transformer_encoder(x).to(self.device)\n",
        "        x = torch.mean(x, dim=0).to(self.device)\n",
        "        x = self.fc(x).to(self.device)\n",
        "        x = x.mean(dim=0, keepdim=True).to(self.device)\n",
        "        return x\n",
        "\n",
        "# Define hyperparameters\n",
        "vocab_size = 100\n",
        "d_model = 100\n",
        "nhead = 5  # Updated: set nhead to 4\n",
        "num_encoder_layers = 3  # Updated: set num_encoder_layers to 3\n",
        "dim_feedforward = 512\n",
        "max_length = 100\n",
        "batch_size = 1\n",
        "num_epochs = 100\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "model = TransformerModel(vocab_size, d_model, nhead, num_encoder_layers, dim_feedforward, max_length).to(device)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3X7W2ZjyUPs"
      },
      "source": [
        "5 HEADS 3 LAYERS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2CI3JVzxSOP",
        "outputId": "3cb3e5aa-33c3-4f36-bde2-68ce5d24c368"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Python312\\Lib\\site-packages\\torch\\nn\\functional.py:5476: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
            "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100, Epoch Accuracy: 73.5204\n",
            "Saved model with accuracy train model with accuracy73.52% to saved_models\\logp_2024-05-01_23-53-29/TE\\train_best_model_73.520.pth\n",
            "Train AUC-ROC: 0.6117, Train F1 Score: 0.8388 , Train Precision: 0.7901, Train Recall: 0.8939\n",
            "\n",
            "Epoch Testing Accuracy : 77.7202\n",
            "Saved model with Test Model with accuracy 77.72% to saved_models\\logp_2024-05-01_23-53-29/TE\\test_best_model_77.720.pth\n",
            "Test AUC-ROC: 0.7073, Test F1 Score: 0.8724, Test Precision: 0.7737, Test Recall: 1.0000\n",
            "\n",
            "Epoch 2/100, Epoch Accuracy: 78.4625\n",
            "Saved model with accuracy train model with accuracy78.46% to saved_models\\logp_2024-05-01_23-53-29/TE\\train_best_model_78.462.pth\n",
            "Train AUC-ROC: 0.6435, Train F1 Score: 0.8726 , Train Precision: 0.8017, Train Recall: 0.9572\n",
            "\n",
            "Epoch Testing Accuracy : 83.9378\n",
            "Saved model with Test Model with accuracy 83.94% to saved_models\\logp_2024-05-01_23-53-29/TE\\test_best_model_83.938.pth\n",
            "Test AUC-ROC: 0.8175, Test F1 Score: 0.8970, Test Precision: 0.8766, Test Recall: 0.9184\n",
            "\n",
            "Epoch 3/100, Epoch Accuracy: 81.8182\n",
            "Saved model with accuracy train model with accuracy81.82% to saved_models\\logp_2024-05-01_23-53-29/TE\\train_best_model_81.818.pth\n",
            "Train AUC-ROC: 0.7364, Train F1 Score: 0.8885 , Train Precision: 0.8424, Train Recall: 0.9398\n",
            "\n",
            "Epoch Testing Accuracy : 85.4922\n",
            "Saved model with Test Model with accuracy 85.49% to saved_models\\logp_2024-05-01_23-53-29/TE\\test_best_model_85.492.pth\n",
            "Test AUC-ROC: 0.8815, Test F1 Score: 0.9085, Test Precision: 0.8742, Test Recall: 0.9456\n",
            "\n",
            "Epoch 4/100, Epoch Accuracy: 82.8554\n",
            "Saved model with accuracy train model with accuracy82.86% to saved_models\\logp_2024-05-01_23-53-29/TE\\train_best_model_82.855.pth\n",
            "Train AUC-ROC: 0.7909, Train F1 Score: 0.8942 , Train Precision: 0.8527, Train Recall: 0.9398\n",
            "\n",
            "Epoch Testing Accuracy : 87.0466\n",
            "Saved model with Test Model with accuracy 87.05% to saved_models\\logp_2024-05-01_23-53-29/TE\\test_best_model_87.047.pth\n",
            "Test AUC-ROC: 0.8753, Test F1 Score: 0.9206, Test Precision: 0.8631, Test Recall: 0.9864\n",
            "\n",
            "Epoch 5/100, Epoch Accuracy: 85.5400\n",
            "Saved model with accuracy train model with accuracy85.54% to saved_models\\logp_2024-05-01_23-53-29/TE\\train_best_model_85.540.pth\n",
            "Train AUC-ROC: 0.8441, Train F1 Score: 0.9116 , Train Precision: 0.8618, Train Recall: 0.9675\n",
            "\n",
            "Epoch Testing Accuracy : 89.1192\n",
            "Saved model with Test Model with accuracy 89.12% to saved_models\\logp_2024-05-01_23-53-29/TE\\test_best_model_89.119.pth\n",
            "Test AUC-ROC: 0.9000, Test F1 Score: 0.9320, Test Precision: 0.8889, Test Recall: 0.9796\n",
            "\n",
            "Epoch 6/100, Epoch Accuracy: 83.8926\n",
            "Train AUC-ROC: 0.8212, Train F1 Score: 0.8994 , Train Precision: 0.8670, Train Recall: 0.9343\n",
            "\n",
            "Epoch Testing Accuracy : 84.9741\n",
            "Test AUC-ROC: 0.8333, Test F1 Score: 0.9061, Test Precision: 0.8642, Test Recall: 0.9524\n",
            "\n",
            "Epoch 7/100, Epoch Accuracy: 82.4893\n",
            "Train AUC-ROC: 0.7945, Train F1 Score: 0.8933 , Train Precision: 0.8422, Train Recall: 0.9509\n",
            "\n",
            "Epoch Testing Accuracy : 84.4560\n",
            "Test AUC-ROC: 0.8858, Test F1 Score: 0.9026, Test Precision: 0.8634, Test Recall: 0.9456\n",
            "\n",
            "Epoch 8/100, Epoch Accuracy: 86.2111\n",
            "Saved model with accuracy train model with accuracy86.21% to saved_models\\logp_2024-05-01_23-53-29/TE\\train_best_model_86.211.pth\n",
            "Train AUC-ROC: 0.8394, Train F1 Score: 0.9146 , Train Precision: 0.8749, Train Recall: 0.9580\n",
            "\n",
            "Epoch Testing Accuracy : 89.1192\n",
            "Saved model with Test Model with accuracy 89.12% to saved_models\\logp_2024-05-01_23-53-29/TE\\test_best_model_89.119.pth\n",
            "Test AUC-ROC: 0.8954, Test F1 Score: 0.9307, Test Precision: 0.9038, Test Recall: 0.9592\n",
            "\n",
            "Epoch 9/100, Epoch Accuracy: 85.2959\n",
            "Train AUC-ROC: 0.8548, Train F1 Score: 0.9084 , Train Precision: 0.8735, Train Recall: 0.9462\n",
            "\n",
            "Epoch Testing Accuracy : 87.0466\n",
            "Test AUC-ROC: 0.8724, Test F1 Score: 0.9186, Test Precision: 0.8812, Test Recall: 0.9592\n",
            "\n",
            "Epoch 10/100, Epoch Accuracy: 85.9060\n",
            "Train AUC-ROC: 0.8636, Train F1 Score: 0.9119 , Train Precision: 0.8794, Train Recall: 0.9470\n",
            "\n",
            "Epoch Testing Accuracy : 88.6010\n",
            "Test AUC-ROC: 0.8829, Test F1 Score: 0.9281, Test Precision: 0.8931, Test Recall: 0.9660\n",
            "\n",
            "Epoch 11/100, Epoch Accuracy: 87.1873\n",
            "Saved model with accuracy train model with accuracy87.19% to saved_models\\logp_2024-05-01_23-53-29/TE\\train_best_model_87.187.pth\n",
            "Train AUC-ROC: 0.8439, Train F1 Score: 0.9205 , Train Precision: 0.8824, Train Recall: 0.9620\n",
            "\n",
            "Epoch Testing Accuracy : 88.0829\n",
            "Test AUC-ROC: 0.9138, Test F1 Score: 0.9265, Test Precision: 0.8735, Test Recall: 0.9864\n",
            "\n",
            "Epoch 12/100, Epoch Accuracy: 87.2483\n",
            "Saved model with accuracy train model with accuracy87.25% to saved_models\\logp_2024-05-01_23-53-29/TE\\train_best_model_87.248.pth\n",
            "Train AUC-ROC: 0.8943, Train F1 Score: 0.9200 , Train Precision: 0.8904, Train Recall: 0.9517\n",
            "\n",
            "Epoch Testing Accuracy : 88.0829\n",
            "Test AUC-ROC: 0.9102, Test F1 Score: 0.9256, Test Precision: 0.8827, Test Recall: 0.9728\n",
            "\n",
            "Epoch 13/100, Epoch Accuracy: 87.8585\n",
            "Saved model with accuracy train model with accuracy87.86% to saved_models\\logp_2024-05-01_23-53-29/TE\\train_best_model_87.858.pth\n",
            "Train AUC-ROC: 0.8951, Train F1 Score: 0.9246 , Train Precision: 0.8866, Train Recall: 0.9660\n",
            "\n",
            "Epoch Testing Accuracy : 89.1192\n",
            "Saved model with Test Model with accuracy 89.12% to saved_models\\logp_2024-05-01_23-53-29/TE\\test_best_model_89.119.pth\n",
            "Test AUC-ROC: 0.9222, Test F1 Score: 0.9307, Test Precision: 0.9038, Test Recall: 0.9592\n",
            "\n",
            "Epoch 14/100, Epoch Accuracy: 87.1263\n",
            "Train AUC-ROC: 0.9057, Train F1 Score: 0.9191 , Train Precision: 0.8908, Train Recall: 0.9493\n",
            "\n",
            "Epoch Testing Accuracy : 89.6373\n",
            "Saved model with Test Model with accuracy 89.64% to saved_models\\logp_2024-05-01_23-53-29/TE\\test_best_model_89.637.pth\n",
            "Test AUC-ROC: 0.9261, Test F1 Score: 0.9333, Test Precision: 0.9150, Test Recall: 0.9524\n",
            "\n",
            "Epoch 15/100, Epoch Accuracy: 88.2245\n",
            "Saved model with accuracy train model with accuracy88.22% to saved_models\\logp_2024-05-01_23-53-29/TE\\train_best_model_88.225.pth\n",
            "Train AUC-ROC: 0.9033, Train F1 Score: 0.9268 , Train Precision: 0.8894, Train Recall: 0.9675\n",
            "\n",
            "Epoch Testing Accuracy : 89.6373\n",
            "Saved model with Test Model with accuracy 89.64% to saved_models\\logp_2024-05-01_23-53-29/TE\\test_best_model_89.637.pth\n",
            "Test AUC-ROC: 0.9190, Test F1 Score: 0.9342, Test Precision: 0.9045, Test Recall: 0.9660\n",
            "\n",
            "Epoch 16/100, Epoch Accuracy: 87.5534\n",
            "Train AUC-ROC: 0.9083, Train F1 Score: 0.9212 , Train Precision: 0.8990, Train Recall: 0.9446\n",
            "\n",
            "Epoch Testing Accuracy : 87.5648\n",
            "Test AUC-ROC: 0.9351, Test F1 Score: 0.9211, Test Precision: 0.8917, Test Recall: 0.9524\n",
            "\n",
            "Epoch 17/100, Epoch Accuracy: 87.4924\n",
            "Train AUC-ROC: 0.9123, Train F1 Score: 0.9213 , Train Precision: 0.8942, Train Recall: 0.9501\n",
            "\n",
            "Epoch Testing Accuracy : 91.1917\n",
            "Saved model with Test Model with accuracy 91.19% to saved_models\\logp_2024-05-01_23-53-29/TE\\test_best_model_91.192.pth\n",
            "Test AUC-ROC: 0.9414, Test F1 Score: 0.9435, Test Precision: 0.9221, Test Recall: 0.9660\n",
            "\n",
            "Epoch 18/100, Epoch Accuracy: 89.2007\n",
            "Saved model with accuracy train model with accuracy89.20% to saved_models\\logp_2024-05-01_23-53-29/TE\\train_best_model_89.201.pth\n",
            "Train AUC-ROC: 0.9316, Train F1 Score: 0.9310 , Train Precision: 0.9171, Train Recall: 0.9454\n",
            "\n",
            "Epoch Testing Accuracy : 92.7461\n",
            "Saved model with Test Model with accuracy 92.75% to saved_models\\logp_2024-05-01_23-53-29/TE\\test_best_model_92.746.pth\n",
            "Test AUC-ROC: 0.9542, Test F1 Score: 0.9536, Test Precision: 0.9290, Test Recall: 0.9796\n",
            "\n",
            "Epoch 19/100, Epoch Accuracy: 89.1397\n",
            "Train AUC-ROC: 0.9266, Train F1 Score: 0.9307 , Train Precision: 0.9157, Train Recall: 0.9462\n",
            "\n",
            "Epoch Testing Accuracy : 89.6373\n",
            "Test AUC-ROC: 0.9512, Test F1 Score: 0.9338, Test Precision: 0.9097, Test Recall: 0.9592\n",
            "\n",
            "Epoch 20/100, Epoch Accuracy: 89.3228\n",
            "Saved model with accuracy train model with accuracy89.32% to saved_models\\logp_2024-05-01_23-53-29/TE\\train_best_model_89.323.pth\n",
            "Train AUC-ROC: 0.9342, Train F1 Score: 0.9318 , Train Precision: 0.9178, Train Recall: 0.9462\n",
            "\n",
            "Epoch Testing Accuracy : 90.1554\n",
            "Test AUC-ROC: 0.9474, Test F1 Score: 0.9369, Test Precision: 0.9156, Test Recall: 0.9592\n",
            "\n",
            "Epoch 21/100, Epoch Accuracy: 89.5668\n",
            "Saved model with accuracy train model with accuracy89.57% to saved_models\\logp_2024-05-01_23-53-29/TE\\train_best_model_89.567.pth\n",
            "Train AUC-ROC: 0.9366, Train F1 Score: 0.9334 , Train Precision: 0.9181, Train Recall: 0.9493\n",
            "\n",
            "Epoch Testing Accuracy : 89.1192\n",
            "Test AUC-ROC: 0.9425, Test F1 Score: 0.9293, Test Precision: 0.9200, Test Recall: 0.9388\n",
            "\n",
            "Epoch 22/100, Epoch Accuracy: 88.7126\n",
            "Train AUC-ROC: 0.9363, Train F1 Score: 0.9275 , Train Precision: 0.9178, Train Recall: 0.9375\n",
            "\n",
            "Epoch Testing Accuracy : 88.6010\n",
            "Test AUC-ROC: 0.9329, Test F1 Score: 0.9281, Test Precision: 0.8931, Test Recall: 0.9660\n",
            "\n",
            "Epoch 23/100, Epoch Accuracy: 89.3838\n",
            "Train AUC-ROC: 0.9354, Train F1 Score: 0.9322 , Train Precision: 0.9179, Train Recall: 0.9470\n",
            "\n",
            "Epoch Testing Accuracy : 89.1192\n",
            "Test AUC-ROC: 0.9327, Test F1 Score: 0.9288, Test Precision: 0.9257, Test Recall: 0.9320\n",
            "\n",
            "Epoch 24/100, Epoch Accuracy: 90.6650\n",
            "Saved model with accuracy train model with accuracy90.67% to saved_models\\logp_2024-05-01_23-53-29/TE\\train_best_model_90.665.pth\n",
            "Train AUC-ROC: 0.9423, Train F1 Score: 0.9408 , Train Precision: 0.9198, Train Recall: 0.9628\n",
            "\n",
            "Epoch Testing Accuracy : 88.0829\n",
            "Test AUC-ROC: 0.9417, Test F1 Score: 0.9236, Test Precision: 0.9026, Test Recall: 0.9456\n",
            "\n",
            "Epoch 25/100, Epoch Accuracy: 89.8109\n",
            "Train AUC-ROC: 0.9465, Train F1 Score: 0.9343 , Train Precision: 0.9288, Train Recall: 0.9398\n",
            "\n",
            "Epoch Testing Accuracy : 88.6010\n",
            "Test AUC-ROC: 0.9370, Test F1 Score: 0.9247, Test Precision: 0.9310, Test Recall: 0.9184\n",
            "\n",
            "Epoch 26/100, Epoch Accuracy: 89.9329\n",
            "Train AUC-ROC: 0.9387, Train F1 Score: 0.9355 , Train Precision: 0.9243, Train Recall: 0.9470\n",
            "\n",
            "Epoch Testing Accuracy : 90.1554\n",
            "Test AUC-ROC: 0.9487, Test F1 Score: 0.9373, Test Precision: 0.9103, Test Recall: 0.9660\n",
            "\n",
            "Epoch 27/100, Epoch Accuracy: 90.1769\n",
            "Train AUC-ROC: 0.9456, Train F1 Score: 0.9369 , Train Precision: 0.9278, Train Recall: 0.9462\n",
            "\n",
            "Epoch Testing Accuracy : 87.5648\n",
            "Test AUC-ROC: 0.9435, Test F1 Score: 0.9211, Test Precision: 0.8917, Test Recall: 0.9524\n",
            "\n",
            "Epoch 28/100, Epoch Accuracy: 89.8719\n",
            "Train AUC-ROC: 0.9441, Train F1 Score: 0.9352 , Train Precision: 0.9222, Train Recall: 0.9485\n",
            "\n",
            "Epoch Testing Accuracy : 91.1917\n",
            "Test AUC-ROC: 0.9564, Test F1 Score: 0.9435, Test Precision: 0.9221, Test Recall: 0.9660\n",
            "\n",
            "Epoch 29/100, Epoch Accuracy: 90.2990\n",
            "Train AUC-ROC: 0.9536, Train F1 Score: 0.9375 , Train Precision: 0.9313, Train Recall: 0.9438\n",
            "\n",
            "Epoch Testing Accuracy : 89.1192\n",
            "Test AUC-ROC: 0.9312, Test F1 Score: 0.9298, Test Precision: 0.9145, Test Recall: 0.9456\n",
            "\n",
            "Epoch 30/100, Epoch Accuracy: 91.3972\n",
            "Saved model with accuracy train model with accuracy91.40% to saved_models\\logp_2024-05-01_23-53-29/TE\\train_best_model_91.397.pth\n",
            "Train AUC-ROC: 0.9596, Train F1 Score: 0.9448 , Train Precision: 0.9349, Train Recall: 0.9549\n",
            "\n",
            "Epoch Testing Accuracy : 89.6373\n",
            "Test AUC-ROC: 0.9545, Test F1 Score: 0.9342, Test Precision: 0.9045, Test Recall: 0.9660\n",
            "\n",
            "Epoch 31/100, Epoch Accuracy: 91.7023\n",
            "Saved model with accuracy train model with accuracy91.70% to saved_models\\logp_2024-05-01_23-53-29/TE\\train_best_model_91.702.pth\n",
            "Train AUC-ROC: 0.9592, Train F1 Score: 0.9463 , Train Precision: 0.9441, Train Recall: 0.9485\n",
            "\n",
            "Epoch Testing Accuracy : 89.1192\n",
            "Test AUC-ROC: 0.9485, Test F1 Score: 0.9302, Test Precision: 0.9091, Test Recall: 0.9524\n",
            "\n",
            "Epoch 32/100, Epoch Accuracy: 90.4820\n",
            "Train AUC-ROC: 0.9450, Train F1 Score: 0.9385 , Train Precision: 0.9348, Train Recall: 0.9422\n",
            "\n",
            "Epoch Testing Accuracy : 88.0829\n",
            "Test AUC-ROC: 0.9161, Test F1 Score: 0.9215, Test Precision: 0.9247, Test Recall: 0.9184\n",
            "\n",
            "Epoch 33/100, Epoch Accuracy: 90.2379\n",
            "Train AUC-ROC: 0.9498, Train F1 Score: 0.9366 , Train Precision: 0.9380, Train Recall: 0.9351\n",
            "\n",
            "Epoch Testing Accuracy : 88.6010\n",
            "Test AUC-ROC: 0.9518, Test F1 Score: 0.9257, Test Precision: 0.9195, Test Recall: 0.9320\n",
            "\n",
            "Epoch 34/100, Epoch Accuracy: 90.7261\n",
            "Train AUC-ROC: 0.9527, Train F1 Score: 0.9400 , Train Precision: 0.9371, Train Recall: 0.9430\n",
            "\n",
            "Epoch Testing Accuracy : 87.5648\n",
            "Test AUC-ROC: 0.9397, Test F1 Score: 0.9205, Test Precision: 0.8968, Test Recall: 0.9456\n",
            "\n",
            "Epoch 35/100, Epoch Accuracy: 91.4582\n",
            "Train AUC-ROC: 0.9562, Train F1 Score: 0.9453 , Train Precision: 0.9336, Train Recall: 0.9572\n",
            "\n",
            "Epoch Testing Accuracy : 87.5648\n",
            "Test AUC-ROC: 0.9228, Test F1 Score: 0.9211, Test Precision: 0.8917, Test Recall: 0.9524\n",
            "\n",
            "Epoch 36/100, Epoch Accuracy: 90.7871\n",
            "Train AUC-ROC: 0.9432, Train F1 Score: 0.9411 , Train Precision: 0.9277, Train Recall: 0.9549\n",
            "\n",
            "Epoch Testing Accuracy : 89.6373\n",
            "Test AUC-ROC: 0.9453, Test F1 Score: 0.9320, Test Precision: 0.9320, Test Recall: 0.9320\n",
            "\n",
            "Epoch 37/100, Epoch Accuracy: 89.8719\n",
            "Train AUC-ROC: 0.9443, Train F1 Score: 0.9346 , Train Precision: 0.9295, Train Recall: 0.9398\n",
            "\n",
            "Epoch Testing Accuracy : 86.0104\n",
            "Test AUC-ROC: 0.9222, Test F1 Score: 0.9121, Test Precision: 0.8750, Test Recall: 0.9524\n",
            "\n",
            "Epoch 38/100, Epoch Accuracy: 88.5906\n",
            "Train AUC-ROC: 0.9325, Train F1 Score: 0.9269 , Train Precision: 0.9151, Train Recall: 0.9390\n",
            "\n",
            "Epoch Testing Accuracy : 88.6010\n",
            "Test AUC-ROC: 0.9542, Test F1 Score: 0.9281, Test Precision: 0.8931, Test Recall: 0.9660\n",
            "\n",
            "Epoch 39/100, Epoch Accuracy: 88.2855\n",
            "Train AUC-ROC: 0.9347, Train F1 Score: 0.9245 , Train Precision: 0.9180, Train Recall: 0.9311\n",
            "\n",
            "Epoch Testing Accuracy : 90.1554\n",
            "Test AUC-ROC: 0.9497, Test F1 Score: 0.9356, Test Precision: 0.9324, Test Recall: 0.9388\n",
            "\n",
            "Epoch 40/100, Epoch Accuracy: 88.8957\n",
            "Train AUC-ROC: 0.9404, Train F1 Score: 0.9282 , Train Precision: 0.9246, Train Recall: 0.9319\n",
            "\n",
            "Epoch Testing Accuracy : 86.0104\n",
            "Test AUC-ROC: 0.9283, Test F1 Score: 0.9103, Test Precision: 0.8896, Test Recall: 0.9320\n",
            "\n",
            "Epoch 41/100, Epoch Accuracy: 90.0549\n",
            "Train AUC-ROC: 0.9394, Train F1 Score: 0.9361 , Train Precision: 0.9277, Train Recall: 0.9446\n",
            "\n",
            "Epoch Testing Accuracy : 87.5648\n",
            "Test AUC-ROC: 0.9364, Test F1 Score: 0.9226, Test Precision: 0.8773, Test Recall: 0.9728\n",
            "\n",
            "Epoch 42/100, Epoch Accuracy: 90.4210\n",
            "Train AUC-ROC: 0.9368, Train F1 Score: 0.9386 , Train Precision: 0.9280, Train Recall: 0.9493\n",
            "\n",
            "Epoch Testing Accuracy : 87.0466\n",
            "Test AUC-ROC: 0.9295, Test F1 Score: 0.9141, Test Precision: 0.9236, Test Recall: 0.9048\n",
            "\n",
            "Epoch 43/100, Epoch Accuracy: 90.4210\n",
            "Train AUC-ROC: 0.9344, Train F1 Score: 0.9382 , Train Precision: 0.9327, Train Recall: 0.9438\n",
            "\n",
            "Epoch Testing Accuracy : 89.6373\n",
            "Test AUC-ROC: 0.9406, Test F1 Score: 0.9329, Test Precision: 0.9205, Test Recall: 0.9456\n",
            "\n",
            "Epoch 44/100, Epoch Accuracy: 86.7602\n",
            "Train AUC-ROC: 0.9147, Train F1 Score: 0.9134 , Train Precision: 0.9211, Train Recall: 0.9058\n",
            "\n",
            "Epoch Testing Accuracy : 91.1917\n",
            "Test AUC-ROC: 0.9573, Test F1 Score: 0.9428, Test Precision: 0.9333, Test Recall: 0.9524\n",
            "\n",
            "Epoch 45/100, Epoch Accuracy: 89.4448\n",
            "Train AUC-ROC: 0.9475, Train F1 Score: 0.9313 , Train Precision: 0.9346, Train Recall: 0.9279\n",
            "\n",
            "Epoch Testing Accuracy : 89.1192\n",
            "Test AUC-ROC: 0.9518, Test F1 Score: 0.9288, Test Precision: 0.9257, Test Recall: 0.9320\n",
            "\n",
            "Epoch 46/100, Epoch Accuracy: 90.2379\n",
            "Train AUC-ROC: 0.9492, Train F1 Score: 0.9378 , Train Precision: 0.9213, Train Recall: 0.9549\n",
            "\n",
            "Epoch Testing Accuracy : 88.0829\n",
            "Test AUC-ROC: 0.9488, Test F1 Score: 0.9251, Test Precision: 0.8875, Test Recall: 0.9660\n",
            "\n",
            "Epoch 47/100, Epoch Accuracy: 87.8585\n",
            "Train AUC-ROC: 0.9332, Train F1 Score: 0.9231 , Train Precision: 0.9018, Train Recall: 0.9454\n",
            "\n",
            "Epoch Testing Accuracy : 91.7098\n",
            "Test AUC-ROC: 0.9602, Test F1 Score: 0.9456, Test Precision: 0.9456, Test Recall: 0.9456\n",
            "\n",
            "Epoch 48/100, Epoch Accuracy: 88.7126\n",
            "Train AUC-ROC: 0.9445, Train F1 Score: 0.9260 , Train Precision: 0.9354, Train Recall: 0.9169\n",
            "\n",
            "Epoch Testing Accuracy : 90.1554\n",
            "Test AUC-ROC: 0.9488, Test F1 Score: 0.9356, Test Precision: 0.9324, Test Recall: 0.9388\n",
            "\n",
            "Epoch 49/100, Epoch Accuracy: 89.2007\n",
            "Train AUC-ROC: 0.9398, Train F1 Score: 0.9298 , Train Precision: 0.9316, Train Recall: 0.9279\n",
            "\n",
            "Epoch Testing Accuracy : 90.6736\n",
            "Test AUC-ROC: 0.9564, Test F1 Score: 0.9396, Test Precision: 0.9272, Test Recall: 0.9524\n",
            "\n",
            "Epoch 50/100, Epoch Accuracy: 87.9805\n",
            "Train AUC-ROC: 0.9136, Train F1 Score: 0.9253 , Train Precision: 0.8879, Train Recall: 0.9660\n",
            "\n",
            "Epoch Testing Accuracy : 89.6373\n",
            "Test AUC-ROC: 0.9422, Test F1 Score: 0.9333, Test Precision: 0.9150, Test Recall: 0.9524\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "current_datetime = datetime.now()\n",
        "formatted_datetime = current_datetime.strftime('%Y-%m-%d_%H-%M-%S')\n",
        "data_name = \"logp\"  # Replace with the actual data name\n",
        "type = \"TE\"  # Replace with the actual type\n",
        "\n",
        "session_name = f'{data_name}_{formatted_datetime}/{type}'\n",
        "folder_path = os.path.join('saved_models', session_name)\n",
        "os.makedirs(folder_path, exist_ok=True)\n",
        "\n",
        "output_dir_train = f'output/{data_name}/train/{type}'\n",
        "os.makedirs(output_dir_train, exist_ok=True)\n",
        "current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "file_name_train = f'{output_dir_train}/train_accuracy_details_{current_time}.txt'\n",
        "\n",
        "output_dir_test = f'output/{data_name}/test'\n",
        "os.makedirs(output_dir_test, exist_ok=True)\n",
        "current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "file_name_test = f'{output_dir_test}/test_accuracy_details_{current_time}.txt'\n",
        "\n",
        "best_train_accuracy = 0.0\n",
        "best_test_accuracy = 0.0\n",
        "\n",
        "# Training loop\n",
        "reconstruction_weight = 0.1  # Weight for the reconstruction loss\n",
        "with open(file_name_train, 'a') as file_train, open(file_name_test, 'a') as file_test:\n",
        "    for epoch in range(50):\n",
        "        total_correct = 0\n",
        "        total_samples = 0\n",
        "        true_labels_train = []\n",
        "        pred_probs_train = []\n",
        "        losses = 0.0\n",
        "\n",
        "        for data_batch in train_dataset:\n",
        "            graph_data_batch = data_batch[0]\n",
        "            sequence_inputs = data_batch[1].to(device)\n",
        "            sequence_targets = graph_data_batch.y\n",
        "\n",
        "            # Zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            output= model(sequence_inputs)\n",
        "\n",
        "            # Compute binary predictions\n",
        "            binary_predictions = (output >= 0.5).float()\n",
        "\n",
        "            # Compute batch accuracy\n",
        "            batch_correct = (binary_predictions == sequence_targets).sum().item()\n",
        "            total_correct += batch_correct\n",
        "            total_samples += 1\n",
        "\n",
        "            output = output.to(device)\n",
        "            sequence_targets = sequence_targets.to(device)\n",
        "\n",
        "            true_labels_train.append(sequence_targets.cpu().numpy().reshape(-1))\n",
        "            pred_probs_train.append(output.detach().cpu().numpy())\n",
        "\n",
        "            # Cast sequence_inputs to float\n",
        "            sequence_inputs = sequence_inputs.float()\n",
        "\n",
        "\n",
        "            # Compute loss\n",
        "            loss = criterion(output, sequence_targets.view(-1))\n",
        "            losses += loss.item()\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "\n",
        "            # Update weights\n",
        "            optimizer.step()\n",
        "\n",
        "        # Compute epoch accuracy\n",
        "        epoch_train_accuracy = (total_correct / total_samples) * 100\n",
        "        print(f\"Epoch {epoch + 1}/{100}, Epoch Accuracy: {epoch_train_accuracy:.4f}\")\n",
        "\n",
        "        if epoch_train_accuracy >= best_train_accuracy:\n",
        "            best_train_accuracy = epoch_train_accuracy\n",
        "            model_path = os.path.join(folder_path, f'train_best_model_{best_train_accuracy:.3f}.pth')\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "            print(\"Saved model with accuracy train model with accuracy{:.2f}% to {}\".format(best_train_accuracy,\n",
        "                                                                                             model_path))\n",
        "\n",
        "        true_labels_train = np.concatenate(true_labels_train)\n",
        "        pred_probs_train = np.concatenate(pred_probs_train)\n",
        "\n",
        "        precision_train = precision_score(true_labels_train, (pred_probs_train >= 0.5).astype(int))\n",
        "        recall_train = recall_score(true_labels_train, (pred_probs_train >= 0.5).astype(int))\n",
        "        auc_roc_train = roc_auc_score(true_labels_train, pred_probs_train)\n",
        "        f1_train = f1_score(true_labels_train, (pred_probs_train >= 0.5).astype(int))\n",
        "        print(\n",
        "            f\"Train AUC-ROC: {auc_roc_train:.4f}, Train F1 Score: {f1_train:.4f} , Train Precision: {precision_train:.4f}, Train Recall: {recall_train:.4f}\\n\")\n",
        "        file_train.write(\n",
        "            f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {losses:.4f}, Train Accuracy: {epoch_train_accuracy:.4f}, Train AUC-ROC: {auc_roc_train:.4f}, Train F1 Score: {f1_train:.4f} , Train Precision: {precision_train:.4f}, Train Recall: {recall_train:.4f}\\n')\n",
        "\n",
        "        total_correct = 0\n",
        "        total_samples = 0\n",
        "        true_labels_test = []\n",
        "        pred_probs_test = []\n",
        "\n",
        "        for data_batch in test_dataset:\n",
        "            graph_data_batch = data_batch[0]\n",
        "            sequence_inputs = data_batch[1].to(device)                                                      \n",
        "            sequence_targets = graph_data_batch.y\n",
        "\n",
        "            output= model(sequence_inputs)\n",
        "            binary_predictions = (output >= 0.5).float()\n",
        "\n",
        "            batch_correct = (binary_predictions == sequence_targets).sum().item()\n",
        "            total_correct += batch_correct\n",
        "            total_samples += 1\n",
        "\n",
        "            true_labels_test.append(sequence_targets.cpu().numpy().reshape(-1))\n",
        "            pred_probs_test.append(output.detach().cpu().numpy())\n",
        "\n",
        "        epoch_test_accuracy = (total_correct / total_samples) * 100\n",
        "        print(f\"Epoch Testing Accuracy : {epoch_test_accuracy:.4f}\")\n",
        "\n",
        "        if epoch_test_accuracy >= best_test_accuracy:\n",
        "            best_test_accuracy = epoch_test_accuracy\n",
        "            model_path = os.path.join(folder_path, f'test_best_model_{best_test_accuracy:.3f}.pth')\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "            print(\"Saved model with Test Model with accuracy {:.2f}% to {}\".format(best_test_accuracy, model_path))\n",
        "\n",
        "        true_labels_test = np.concatenate(true_labels_test)\n",
        "        pred_probs_test = np.concatenate(pred_probs_test)\n",
        "        #pred_probs_test.append(output.detach().cpu().numpy().reshape(-1))\n",
        "        \n",
        "        #print(true_labels_test, pred_probs_test)\n",
        "        precision_test = precision_score(true_labels_test, (pred_probs_test >= 0.5).astype(int))\n",
        "        recall_test = recall_score(true_labels_test, (pred_probs_test >= 0.5).astype(int))\n",
        "        auc_roc_test = roc_auc_score(true_labels_test, pred_probs_test)\n",
        "        f1_test = f1_score(true_labels_test, (pred_probs_test >= 0.5).astype(int))\n",
        "        print(\n",
        "            f\"Test AUC-ROC: {auc_roc_test:.4f}, Test F1 Score: {f1_test:.4f}, Test Precision: {precision_test:.4f}, Test Recall: {recall_test:.4f}\\n\")\n",
        "        file_test.write(\n",
        "            f'Epoch {epoch + 1}/{num_epochs}, Test Accuracy: {epoch_test_accuracy:.4f},Test AUC-ROC: {auc_roc_test:.4f}, Test F1 Score: {f1_test:.4f}, Test Precision: {precision_test:.4f}, Test Recall: {recall_test:.4f} \\n')\n",
        "file_test.close()\n",
        "file_train.close()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
